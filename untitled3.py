# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15h9Y_3g88IzKAHQva15U-g3qFq2IG75z
"""

# importing libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Dropout

# splitting Data from raw file
train_data = pd.read_csv("Google_Stock_Price_Train.csv")
test_data = pd.read_csv("Google_Stock_Price_Test.csv")

training_prices = train_data['Open'].values.reshape(-1, 1)
testing_prices = test_data['Open'].values.reshape(-1, 1)

# min max scalling
scaler = MinMaxScaler(feature_range=(0, 1))
training_scaled = scaler.fit_transform(training_prices)

def create_datasets(data, time_steps=60):
    X, y = [], []
    for i in range(time_steps, len(data)):
        X.append(data[i - time_steps:i, 0])
        y.append(data[i, 0])
    return np.array(X), np.array(y)

time_steps = 60
X_train, y_train = create_datasets(training_scaled, time_steps)

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)

total_data = np.concatenate((training_prices, testing_prices))
inputs = total_data[len(total_data) - len(testing_prices) - time_steps:]
inputs_scaled = scaler.transform(inputs)

X_test, y_test = create_datasets(inputs_scaled, time_steps)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# building RNN model


def build_rnn(model_type="LSTM", units=50, dropout_rate=0.2):
    model = Sequential()

    if model_type == "LSTM":
        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1)))
        model.add(Dropout(dropout_rate))
        model.add(LSTM(units=units, return_sequences=False))

    elif model_type == "GRU":
        model.add(GRU(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1)))
        model.add(Dropout(dropout_rate))
        model.add(GRU(units=units, return_sequences=False))

    elif model_type == "SimpleRNN":
        model.add(SimpleRNN(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1)))
        model.add(Dropout(dropout_rate))
        model.add(SimpleRNN(units=units, return_sequences=False))

    model.add(Dropout(dropout_rate))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')

    return model

# training and evaluating model

def train_and_evaluate(model_type, units, dropout_rate, epochs=50, batch_size=32):
    print(f"Training {model_type} model...")
    model = build_rnn(model_type=model_type, units=units, dropout_rate=dropout_rate)
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)

    # predicting on the test set

    predictions = model.predict(X_test)
    predictions = scaler.inverse_transform(predictions)
    actual = scaler.inverse_transform(y_test.reshape(-1, 1))

    # performance metrics

    rmse = np.sqrt(mean_squared_error(actual, predictions))
    mae = mean_absolute_error(actual, predictions)
    r2 = r2_score(actual, predictions)

    # visualization of outcome
    plt.figure(figsize=(10, 6))
    plt.plot(actual, color='blue', label='Actual Prices')
    plt.plot(predictions, color='red', label='Predicted Prices')
    plt.title(f'{model_type} Model Predictions')
    plt.legend()
    plt.show()

    return rmse, mae, r2

# experiments and analysis

results = {}
for model_type in ["LSTM", "GRU", "SimpleRNN"]:
    rmse, mae, r2 = train_and_evaluate(model_type, units=50, dropout_rate=0.2, epochs=50, batch_size=32)
    results[model_type] = {"RMSE": rmse, "MAE": mae, "R2": r2}
    print(f"{model_type} Results -> RMSE: {rmse:.3f}, MAE: {mae:.3f}, R2: {r2:.3f}")

results_df = pd.DataFrame(results).T
print("Performance Comparison:")
print(results_df)